services:
  database:
    image: ankane/pgvector
    restart: always
    env_file:
      - .env
    volumes:
      - dx:/var/lib/postgresql
    ports:
      - $POSTGRES_PORT:5432
    networks:
      - app

  actions:
    image: actions
    build: actions
    restart: always
    ports:
      - 9000:80
    depends_on:
      - database
    networks:
      - app

  graphql:
    image: hasura/graphql-engine:v2.40.0.cli-migrations-v3
    volumes:
      - ./hasura/migrations:/hasura-migrations
      - ./hasura/metadata:/hasura-metadata
      - ./hasura/seeds:/hasura-seeds
    ports:
      - "8080:8080"
    depends_on:
      - database
    restart: always
    environment:
      ## postgres database to store Hasura metadata
      HASURA_GRAPHQL_METADATA_DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@database:5432/${POSTGRES_DB}
      ## this env var can be used to add the above postgres database to Hasura as a data source. this can be removed/updated based on your needs
      PG_DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@database:5432/${POSTGRES_DB}
      ## enable the console served by server
      HASURA_GRAPHQL_ENABLE_CONSOLE: "true" # set to "false" to disable console
      ## enable debugging mode. It is recommended to disable this in production
      HASURA_GRAPHQL_DEV_MODE: "true"
      HASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, webhook-log, websocket-log, query-log
      ## uncomment next line to set an admin secret
      HASURA_GRAPHQL_ADMIN_SECRET: ${HASURA_ADMIN_SECRET}
    networks:
      - app

  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    #pull_policy: always
    #tty: true
    #   environment:
    #   - OLLAMA_KEEP_ALIVE=24h
    #   - OLLAMA_HOST=0.0.0.0
    restart: always
    networks:
       - app



  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8090:8080
    environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
      - OLLAMA_BASE_URLS=http://host.docker.internal:11434 
      - WEBUI_URL=http://localhost:8090
      - ENV=dev
      - WEBUI_AUTH=False
      - WEBUI_NAME=team_standup
      - WEBUI_URL=http://localhost:8090
      - WEBUI_SECRET_KEY=t0p-s3cr3t
    restart: unless-stopped
    networks:
       - app

networks:
  app:

volumes:
  dx:
  ollama:
  external: true
  ollama-webui:
  external: true
